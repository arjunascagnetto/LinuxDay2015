{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>L'iconografia tecnologica del Grande Elefante Giallo nella Tribu' degli Apache </h2></center>\n",
    "<p><center><img src=\"http://bigdatainterviewquestions.com/wp-content/uploads/2014/10/Hadoop-Interview-Questions.jpeg\" alt=\"Drawing\" style=\"width: 200px;\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h4>Mai uguale, veloce e voluminosa. Se una sorgente di informazioni ha queste caratteristiche quali sono gli strumenti open source che possiamo usare per gestirla ? Facciamoci aiutare da alcuni componenti della numerosa tribù degli Apache. Hadoop, HBase, Pig, Hive, Mahout, Spark sono solo alcuni dei 30 membri della tribù, ci presenteremo e vedremo cosa hanno da dirci sul Grande Elefante Giallo</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mai uguale, veloce, voluminosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nel 2001 l'analista Doug Laney nell'articolo [\"3D data management: Controlling data volume, variety and velocity\"](http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf), introduce il concetto delle 3V dei [Big Data](https://en.wikipedia.org/wiki/Big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Volume\n",
    "- Velocity\n",
    "- Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ad alcuni piace dare una veste grafica a queste grandezze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://itknowledgeexchange.techtarget.com/writing-for-business/files/2013/02/BigData.001.jpg\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Volume**\n",
    "\n",
    "E' decisamente la grandezza piu' nota ai media ed anche la piu' facilmente associabile alla parola \"big\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Caratterizza la quantita' di dati da processare, analizzare, ripulire, gestire, salvare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Facebook afferma che il suo database aumenta di circa [600TB al giorno](https://code.facebook.com/posts/229861827208629/scaling-the-facebook-data-warehouse-to-300-pb/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "La API 2.0 di Facebook introdotta nel 2014 non permette l'accesso a molti elementi che la precedente API autorizzava. Ad esempio la lista degli amici dei vostri amici. Per aggirare il problema dovete scrivere una app e farla accettare dai vostri amici.\n",
    "\n",
    "[Link](http://stackoverflow.com/questions/23417356/facebook-graph-api-v2-0-me-friends-returns-empty-or-only-friends-who-also-u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Velocity**\n",
    "\n",
    "Una grandezza che caratterizza la velocita' con la quale arrivano nuovi dati, da immagazzinare, gestire, processare, analizzare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Internet Live stats](http://www.internetlivestats.com/)\n",
    "[World Meters](http://www.worldometers.info/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Variety**\n",
    "\n",
    "Si tratta di una grandezza che va a quantificare quanto sono eterogenei i dati da immagazzinare, analizzare, processare, gestire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "E' la grandezza meno conosciuta, ma che crea piu' difficolta' nel trattarla e probabilmente e' anche la piu' interessante, o meglio la piu' densa di novita'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L'eterogenita' si presenta quando si incrociano informazioni da origini diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esempio: testo, dati geografici, foto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Anche presi singolarmente i dati testo e i dati foto sono di difficile trattazione e richiedono spesso accorgimenti ad hoc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quali sono allora le risposte OpenSource alla domanda del mercato per il trattamenteo dei BigData ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La [Apache Software Foundation](http://www.apache.org/) **ASF** si e' preoccupata di acquisire e ridistribuire software e tecnologie che hanno avuto, hanno e avranno un posto speciale nell'ecosistema dei BigData."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[ASF BigData Category](http://projects-old.apache.org/indexes/category.html#big-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ... e fu fatto <a href=\"https://hadoop.apache.org/\"><img src=\"https://hadoop.apache.org/images/hadoop-logo.jpg\" style=\"width: 300px;\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Padre indiscusso del movimento Bigdata e' stato creato da [Doug Cutting](https://en.wikipedia.org/wiki/Doug_Cutting) e [Mike Cafarella](https://en.wikipedia.org/wiki/Mike_Cafarella) nel 2005. Tutto parte da Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Si mormora che il logo e il nome derivino dal pupazzo di peluche del figlio di Doug Cutting, appunto un elefante giallo di nome Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Che cosa e' Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Haddop e' una libreria di programmi, scritti in Java e C, che fornisce un [framework](https://it.wikipedia.org/wiki/Framework) (struttura) per l'elaborazione di grandi insiemi di dati distribuiti su un [cluster](https://it.wikipedia.org/wiki/Computer_cluster) di macchine attraverso l'uso di un modello di programmazione molto diretto.\n",
    "\n",
    "> The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Non ha problemi di scala. Puo' andare da un cluster con pochi nodi (anche uno solo) fino a migliaia di macchine.\n",
    "\n",
    "> It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "quindi l'alta affidabilita' del sistema e' ottenuta non attraverso costosi componenti hardware di controllo, ma proprio sulla base della libreria Hadoop stessa.\n",
    "\n",
    "> Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Piu' in dettaglio come e' costruito un cluster Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nel framework possiamo individuare 4 moduli:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Core \n",
    "- Hdfs\n",
    "- Yarn (solo in hadoop 2.0)\n",
    "- Map/Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Di questi il ***core*** e' l'insieme delle funzioni di base, essenzialmente tutto il corredo di codice che serve per far funzionare gli altri tre moduli. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Yarn*** acronimo di Yet Another Resource Negotiator. E' una evoluzione del Map/Reduce negotiator, il modulo che .... ma non ce ne occuperemo oggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Hdfs*** e' il file system distribuito di Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- alcuni lo chiamano Hierarchical Distributed FileSystem \n",
    "- altri piu' semplicemente HaDoop FileSystem \n",
    "- e altri ancora Hadoop Distributed FileSystem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**[Map/Reduce](https://en.wikipedia.org/wiki/MapReduce)** e' un modello di calcolo.\n",
    "\n",
    "- \"Map\" step: Each worker node applies the \"map()\" function to the local data, and writes the output to a temporary storage. A master node orchestrates that for redundant copies of input data, only one is processed.\n",
    "- \"Shuffle\" step: Worker nodes redistribute data based on the output keys (produced by the \"map()\" function), such that all data belonging to one key is located on the same worker node.\n",
    "- \"Reduce\" step: Worker nodes now process each group of output data, per key, in parallel.\n",
    "\n",
    "Ci sono cose che un programma scritto per il Map/Reduce non fanno bene e ci sono altre cose che fanno molto bene.\n",
    "\n",
    "Mediana non funziona bene perche' tutte le macchine devono accedere a tutto il datatset.\n",
    "Cosa fa bene ??!?!??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cosa non e' Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Premessa.\n",
    "\n",
    "- > Nel calcolo parallelo tutti i processori devono accedere ad una memoria condivisa. La memoria condivisa può essere usata per lo scambio di informazioni tra i processori.\n",
    "\n",
    "- > Nel calcolo distribuito ogni processore ha la propria memoria privata (memoria distribuita). Le informazioni sono scambiate grazie al passaggio di messaggi tra i processori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Non e' calcolo parallelo propriamente detto poiche' non abbiamo condivisione di memoria tra i processori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I processori stanno su macchine diverse che comunicano tramite rete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "E' quindi un calcolo parallelo e distribuito, poiche' di fatto i calcoli avvengono contemporaneamente su diversi processori distribuiti nel cluster. \n",
    "\n",
    "Tutto questo per dire che non si possono usare tecnologie e paradigmi di programmazione esplicitamnete studiati per il calcolo parallelo ne' per quello distribuito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spiegazione dell' hdfs con esempi su cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spiegazione del Map/Reduce usando il word count con codice cineca-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### MRJob pythonic way to write map-reduce programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[MRJob](https://pythonhosted.org/mrjob/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src =\"http://hbase.apache.org/images/hbase_logo.png\" style=\"width: 300px;\"/ >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Database distribuito su HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table><tr><td><img src=\"https://pig.apache.org/images/pig-logo.gif\" style=\"width: 100px;\" /></td><td><img src=\"https://hive.apache.org/images/hive_logo_medium.jpg\" style=\"width: 100px;\" /></td></tr><tr><td><center>Pig</center></td> <td><center>Hive</center></td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Pig is a high-level platform for creating MapReduce programs used with Hadoop. The language for this platform is called Pig Latin.[1] Pig Latin abstracts the programming from the Java MapReduce idiom into a notation which makes MapReduce programming high level, similar to that of SQL for RDBMS systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Pig Latin\n",
    "Users =\n",
    "load\n",
    "‘users’\n",
    "as\n",
    "(name, age);\n",
    "Fltrd = \n",
    "filter\n",
    "Users\n",
    "by\n",
    "age >= 18\n",
    "and\n",
    "age <= 25;\n",
    "Pages =\n",
    "load\n",
    "‘pages’\n",
    "as\n",
    "(user,\n",
    "url\n",
    ");\n",
    "Jnd\n",
    "=\n",
    "join\n",
    "Fltrd\n",
    "by\n",
    "name, Pages\n",
    "by\n",
    "user;\n",
    "Grpd\n",
    "=\n",
    "group\n",
    "Jnd\n",
    "by\n",
    "url\n",
    ";\n",
    "Smmd\n",
    "=\n",
    "foreach\n",
    "Grpd\n",
    "generate\n",
    "group,\n",
    "COUNT(Jnd\n",
    ")\n",
    "as\n",
    "clicks;\n",
    "Srtd\n",
    "=\n",
    "order\n",
    "Smmd\n",
    "by\n",
    "clicks\n",
    "desc\n",
    ";\n",
    "Top5\n",
    "=\n",
    "limit\n",
    "Srtd\n",
    "5\n",
    ";\n",
    "store\n",
    "Top5\n",
    "into\n",
    "‘\n",
    "top5sites\n",
    "’\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Codice MR in Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> The Apache Hive ™ data warehouse software facilitates querying and managing large datasets residing in distributed storage. Hive provides a mechanism to project structure onto this data and query the data using a SQL-like language called HiveQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Apache Hive supports analysis of large datasets stored in Hadoop's HDFS and compatible file systems such as Amazon S3 filesystem. It provides an SQL-like language called HiveQL[6] with schema on read and transparently converts queries to map/reduce, Apache Tez[7] and Spark jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://mahout.apache.org/images/mahout-logo-brudman.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Libreria per il machine learning su Map/Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://spark.apache.org/images/spark-logo.png\" style=\"width: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La stella scintillante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://spark.apache.org/images/spark-stack.png\" style=\"width: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
