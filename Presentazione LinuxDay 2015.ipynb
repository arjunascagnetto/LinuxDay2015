{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>L'iconografia tecnologica del Grande Elefante Giallo nella Tribu' degli Apache </h2></center>\n",
    "<p><center><img src=\"http://bigdatainterviewquestions.com/wp-content/uploads/2014/10/Hadoop-Interview-Questions.jpeg\" alt=\"Drawing\" style=\"width: 200px;\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h4>Mai uguale, veloce e voluminosa. Se una sorgente di informazioni ha queste caratteristiche quali sono gli strumenti open source che possiamo usare per gestirla ? Facciamoci aiutare da alcuni componenti della numerosa tribù degli Apache. Hadoop, HBase, Pig, Hive, Mahout, Spark sono solo alcuni dei 30 membri della tribù, ci presenteremo e vedremo cosa hanno da dirci sul Grande Elefante Giallo</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Le 3 V dei BigData. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Veloce spiegazione della prima riga dell'abstract:\"Mai uguale, Variety, veloce, Velocity, voluminosa. Volume\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduzione ad [Hadoop](https://hadoop.apache.org/) <img src=\"https://hadoop.apache.org/images/hadoop-logo.jpg\" style=\"width: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Creato da [Doug Cutting](https://en.wikipedia.org/wiki/Doug_Cutting) e [Mike Cafarella](https://en.wikipedia.org/wiki/Mike_Cafarella) nel 2005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Si mormora che il logo e il nome derivino dal pupazzo di peluche del figio di Doug Cutting, appunto un elefante giallo di nome Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Che cosa e' Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Haddop e' una libreria di programmi, scritti in Java e C, che fornisce un [framework](https://it.wikipedia.org/wiki/Framework) (struttura) per l'elaborazione di grandi insiemi di dati distribuiti su un [cluster](https://it.wikipedia.org/wiki/Computer_cluster) di macchine attraverso l'uso di un modello di programmazione molto diretto.\n",
    "\n",
    "> The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Non ha problemi di scala. Puo' andare da un cluster con pochi nodi (anche uno solo) fino a migliaia di macchine.\n",
    "\n",
    "> It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "quindi l'alta affidabilita' del sistema e' ottenuta non attraverso costosi componenti hardware di controllo, ma proprio sulla base della libreria Hadoop stessa.\n",
    "\n",
    "> Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Piu' in dettaglio come e' costruito un cluster Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nel framework possiamo individuare 4 moduli:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Core \n",
    "- Hdfs\n",
    "- Yarn (solo in hadoop 2.0)\n",
    "- Map/Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Di questi il core e' l'insieme delle funzioni di base, essenzialmente tutto il corredo di codice che serve per far funzionare gli altri tre moduli. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Yarn acronimo di Yet Another Resource Negotiator. E' una evoluzione del Map/Reduce negotiator, il modulo che .... ma non ce ne occuperemo oggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hdfs - il file sistem distribuito di Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###### - alcuni lo chiamno Hierarchical Distributed FileSystem \n",
    "###### - altri piu' semplicemente HaDoop FileSystem \n",
    "###### - e altri ancora Hadoop Distributed FileSystem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Map/Reduce](https://en.wikipedia.org/wiki/MapReduce) e' un modello di calcolo.\n",
    "\n",
    "- \"Map\" step: Each worker node applies the \"map()\" function to the local data, and writes the output to a temporary storage. A master node orchestrates that for redundant copies of input data, only one is processed.\n",
    "- \"Shuffle\" step: Worker nodes redistribute data based on the output keys (produced by the \"map()\" function), such that all data belonging to one key is located on the same worker node.\n",
    "- \"Reduce\" step: Worker nodes now process each group of output data, per key, in parallel.\n",
    "\n",
    "Ci sono cose che un programma scritto per il Map/Reduce non fanno bene e ci sono altre cose che fanno molto bene.\n",
    "\n",
    "Mediana non funziona bene perche' tutte le macchine devono accedere a tutto i datatset.\n",
    "Cosa fa bene ??!?!??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cosa non e' Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Premessa.\n",
    "\n",
    "- > Nel calcolo parallelo tutti i processori devono accedere ad una memoria condivisa. La memoria condivisa può essere usata per lo scambio di informazioni tra i processori.\n",
    "\n",
    "- > Nel calcolo distribuito ogni processore ha la propria memoria privata (memoria distribuita). Le informazioni sono scambiate grazie al passaggio di messaggi tra i processori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Non e' calcolo parallelo propriamente detto poiche' non abbiamo condivisione di memoria tra i processori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I processori stanno su macchine diverse che comunicano tramite rete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' quindi un calcolo parallelo e distribuito, poiche' di fatto i calcoli avvengono contemporaneamente su diversi processori distribuiti nel cluster. \n",
    "\n",
    "Tutto questo per dire che non si possono usare tecnologie e paradigmi di programmazione esplicitamnete studiati per il calcolo parallelo ne' per quello distribuito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spiegazione dell' hdfs con esempi su cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spiegazione del Map/Reduce usando il word count con codice cineca-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pig/Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mahout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
